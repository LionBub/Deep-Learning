{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up training and testing data\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "np.random.seed(1)\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "input_rows, input_cols = (28, 28)\n",
    "pixels_per_image = input_rows * input_cols\n",
    "num_labels = 10 # [0, 9]\n",
    "\n",
    "images =  x_train[0:1000].reshape(1000, pixels_per_image) / 255\n",
    "categorical_labels = y_train[0:1000] # looks something like [2, 5, 1, 8, 0, ...]\n",
    "\n",
    "one_hot_labels = np.zeros((len(categorical_labels), 10))\n",
    "for batch, l in enumerate(categorical_labels):\n",
    "    one_hot_labels[batch][l] = 1   # so if the number we are given is a 3, the label is [0, 0, 0, 1, 0, ...]\n",
    "labels = one_hot_labels \n",
    "\n",
    "test_images = x_test.reshape(len(x_test), pixels_per_image) / 255\n",
    "test_labels = np.zeros((len(y_test), 10))\n",
    "for batch, l in enumerate(y_test):\n",
    "    test_labels[batch][l] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define activation functions and their derivative functions\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "def tanh_deriv(output):\n",
    "    return 1 - (output ** 2)\n",
    "def softmax(x):\n",
    "    temp = np.exp(x)\n",
    "    return temp / np.sum(temp, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure model\n",
    "alpha = 2\n",
    "iterations = 300\n",
    "batch_size = 128\n",
    "kernel_rows, kernel_cols = (3, 3)\n",
    "num_kernels = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize weights\n",
    "hidden_size = ((input_rows - kernel_rows) * (input_cols - kernel_cols)) * num_kernels\n",
    "kernel_weights = 0.02 * np.random.random((kernel_rows * kernel_cols, num_kernels)) - 0.01\n",
    "weights_1_2 = 0.2 * np.random.random((hidden_size, num_labels)) - 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### network shape: \n",
    "28 * 28 = 784  \n",
    "convoluted layer with  16 3*3 kernel  \n",
    "25 * 25 * 16 = 10,000 hidden layer  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_section(layer, row_from, row_to, col_from, col_to):\n",
    "    section = layer[ : , row_from : row_to, col_from : col_to]\n",
    "    return section.reshape(-1, 1, row_to - row_from, col_to - col_from)\n",
    "# The first dimension (-1 in this case) represents the batch size. The use of -1 allows NumPy to automatically infer this dimension based on the size of the input array.\n",
    "# The second dimension (1 in this case) represents the number of channels. For grayscale images, this is typically 1, while for RGB images, it would be 3.\n",
    "# The third and fourth dimensions represent the height and width of the section extracted from the original image.\n",
    "# from ChatGPT, might not be correct. I dont fully understand why the kernels are four dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def printAccuracy(test_correct_cnt, correct_cnt, j):\n",
    "    sys.stdout.write(\"\\n\" + \\\n",
    "            \"I: \" + str(j) + \\\n",
    "            \" Test-Acc: \" + str(test_correct_cnt / float(len(test_images))) + \\\n",
    "            \" Train-Acc \" + str(correct_cnt / float(len(images))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_convelution(layer_0):\n",
    "    sections = list()\n",
    "    for row_start in range(layer_0.shape[1] - kernel_rows):\n",
    "        for col_start in range(layer_0.shape[2] - kernel_cols):\n",
    "            sect = get_image_section(layer_0, row_start, row_start + kernel_rows, col_start, col_start + kernel_cols)\n",
    "            sections.append(sect)\n",
    "\n",
    "    expanded_input = np.concatenate(sections, axis=1)\n",
    "    expanded_shape = expanded_input.shape\n",
    "    flattened_input = expanded_input.reshape(expanded_shape[0] * expanded_shape[1], -1)\n",
    "\n",
    "    kernel_output = flattened_input.dot(kernel_weights)\n",
    "    return kernel_output, expanded_shape, flattened_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I: 0 Test-Acc: 0.0288 Train-Acc 0.055\n",
      "I: 1 Test-Acc: 0.0273 Train-Acc 0.037\n",
      "I: 2 Test-Acc: 0.028 Train-Acc 0.037"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m         kernel_output, expanded_shape, flattened_input \u001b[38;5;241m=\u001b[39m apply_convelution(layer_0)\n\u001b[1;32m     41\u001b[0m         layer_1 \u001b[38;5;241m=\u001b[39m tanh(kernel_output\u001b[38;5;241m.\u001b[39mreshape(expanded_shape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 42\u001b[0m         layer_2 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_1_2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m         test_correct_cnt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39margmax(layer_2) \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(test_labels[image:image\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(iteration \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for iteration in range(iterations):\n",
    "    correct_cnt = 0\n",
    "    for batch in range(int(len(images) / batch_size)):\n",
    "        # get and format layer_0\n",
    "        batch_start, batch_end = ((batch * batch_size), ((batch + 1) * batch_size))\n",
    "        layer_0 = images[batch_start : batch_end]\n",
    "        layer_0 = layer_0.reshape(layer_0.shape[0], 28, 28)\n",
    "\n",
    "        # run neural network\n",
    "        kernel_output, expanded_shape, flattened_input  = apply_convelution(layer_0) \n",
    "        layer_1 = tanh(kernel_output.reshape(expanded_shape[0], -1))\n",
    "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
    "        layer_1 *= dropout_mask * 2\n",
    "        layer_2 = softmax(np.dot(layer_1, weights_1_2))\n",
    "\n",
    "        # get batch correctness\n",
    "        for image_in_batch in range(batch_size):\n",
    "            labelset = labels[batch_start + image_in_batch : batch_start + image_in_batch + 1]\n",
    "            increment = int(np.argmax(layer_2[image_in_batch : image_in_batch + 1]) == np.argmax(labelset))\n",
    "            correct_cnt += increment\n",
    "\n",
    "        # calculate deltas\n",
    "        layer_2_delta = (labels[batch_start : batch_end] - layer_2) / (batch_size * layer_2.shape[0])\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * tanh_deriv(layer_1)\n",
    "        layer_1_delta *= dropout_mask\n",
    "\n",
    "        # backpropagate\n",
    "        weights_1_2 += alpha * layer_1.T.dot(layer_2_delta)\n",
    "        layer_1_derivative_reshape = layer_1_delta.reshape(kernel_output.shape)\n",
    "        k_update = flattened_input.T.dot(layer_1_derivative_reshape)\n",
    "        kernel_weights -= alpha * k_update\n",
    "\n",
    "    test_correct_cnt = 0\n",
    "\n",
    "    # run test set\n",
    "    for image in range(len(test_images)):\n",
    "            layer_0 = test_images[image:image+1]\n",
    "            layer_0 = layer_0.reshape(layer_0.shape[0], 28, 28)\n",
    "\n",
    "            kernel_output, expanded_shape, flattened_input = apply_convelution(layer_0)\n",
    "            layer_1 = tanh(kernel_output.reshape(expanded_shape[0], -1))\n",
    "            layer_2 = np.dot(layer_1, weights_1_2)\n",
    "            test_correct_cnt += int(np.argmax(layer_2) == np.argmax(test_labels[image:image+1]))\n",
    "    if(iteration % 1 == 0):\n",
    "        printAccuracy(test_correct_cnt, correct_cnt, iteration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
